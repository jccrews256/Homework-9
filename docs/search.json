[
  {
    "objectID": "Homework 9.html",
    "href": "Homework 9.html",
    "title": "Homework 9",
    "section": "",
    "text": "Introduction\nThe goal of this work is to practice fitting models and evaluating the predictive ability of those models within the tidymodels framework. For this practice, we will use bike share rental data from the Seoul bike share program. The goal will be to effectively predict daily bike share rentals.\nNote that this file includes the work I completed for Homework 8.\n\n\nLoading Packages\nBefore getting started, we need to load in some packages.\n\n#Loading packages\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.3\n\n\nWarning: package 'tidyr' was built under R version 4.3.3\n\n\nWarning: package 'purrr' was built under R version 4.3.3\n\n\nWarning: package 'dplyr' was built under R version 4.3.3\n\n\nWarning: package 'forcats' was built under R version 4.3.3\n\n\nWarning: package 'lubridate' was built under R version 4.3.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   4.0.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.3.0 ──\n✔ broom        1.0.10     ✔ rsample      1.3.1 \n✔ dials        1.4.2      ✔ tune         2.0.1 \n✔ infer        1.0.9      ✔ workflows    1.3.0 \n✔ modeldata    1.5.1      ✔ workflowsets 1.1.1 \n✔ parsnip      1.3.3      ✔ yardstick    1.3.2 \n✔ recipes      1.3.1      \n\n\nWarning: package 'yardstick' was built under R version 4.3.3\n\n\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n\nlibrary(broom)\nlibrary(knitr)\nlibrary(skimr)\nlibrary(kableExtra)\n\nWarning: package 'kableExtra' was built under R version 4.3.3\n\n\n\nAttaching package: 'kableExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nlibrary(patchwork)\nlibrary(rsample)\nlibrary(glmnet)\n\nWarning: package 'glmnet' was built under R version 4.3.3\n\n\nLoading required package: Matrix\n\n\nWarning: package 'Matrix' was built under R version 4.3.3\n\n\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nLoaded glmnet 4.1-8\n\nlibrary(baguette)\n\nWarning: package 'baguette' was built under R version 4.3.3\n\nlibrary(ranger)\n\nWarning: package 'ranger' was built under R version 4.3.3\n\nlibrary(vip)\n\nWarning: package 'vip' was built under R version 4.3.3\n\n\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n\n#Ensuring we don't print in scientific notation\noptions(scipen = 999,pillar.sigfig = 7)\n\n\n\nReading in Data\nNow we will read in the Seoul bike share data. In the code chunk below, note that we must specify that the encoding is “latin1” in order to read in the data without error.\n\nbike_share_data&lt;-read_csv(\"https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv\",\n                          locale = locale(encoding = \"latin1\"))\n\nRows: 8760 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): Date, Seasons, Holiday, Functioning Day\ndbl (10): Rented Bike Count, Hour, Temperature(°C), Humidity(%), Wind speed ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\nExploratory Data Analysis\n\nChecking the Data\nBefore we model the data, we need to do some standard validation checks.\nFirst, we will check whether any of the variables have missing values.\n\n#Capturing number of missing values by variable\nbike_share_data |&gt;\n  summarize(across(everything(),~sum(is.na(.x))))\n\n# A tibble: 1 × 14\n   Date `Rented Bike Count`  Hour `Temperature(°C)` `Humidity(%)`\n  &lt;int&gt;               &lt;int&gt; &lt;int&gt;             &lt;int&gt;         &lt;int&gt;\n1     0                   0     0                 0             0\n# ℹ 9 more variables: `Wind speed (m/s)` &lt;int&gt;, `Visibility (10m)` &lt;int&gt;,\n#   `Dew point temperature(°C)` &lt;int&gt;, `Solar Radiation (MJ/m2)` &lt;int&gt;,\n#   `Rainfall(mm)` &lt;int&gt;, `Snowfall (cm)` &lt;int&gt;, Seasons &lt;int&gt;, Holiday &lt;int&gt;,\n#   `Functioning Day` &lt;int&gt;\n\n\nImpressively, none of the variables have missing values. This is a great dataset!\nNext, we will confirm that the variable/column types set by read_csv are logical.\n\n#Checking variable types\nstr(bike_share_data)\n\nspc_tbl_ [8,760 × 14] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Date                     : chr [1:8760] \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" \"01/12/2017\" ...\n $ Rented Bike Count        : num [1:8760] 254 204 173 107 78 100 181 460 930 490 ...\n $ Hour                     : num [1:8760] 0 1 2 3 4 5 6 7 8 9 ...\n $ Temperature(°C)          : num [1:8760] -5.2 -5.5 -6 -6.2 -6 -6.4 -6.6 -7.4 -7.6 -6.5 ...\n $ Humidity(%)              : num [1:8760] 37 38 39 40 36 37 35 38 37 27 ...\n $ Wind speed (m/s)         : num [1:8760] 2.2 0.8 1 0.9 2.3 1.5 1.3 0.9 1.1 0.5 ...\n $ Visibility (10m)         : num [1:8760] 2000 2000 2000 2000 2000 ...\n $ Dew point temperature(°C): num [1:8760] -17.6 -17.6 -17.7 -17.6 -18.6 -18.7 -19.5 -19.3 -19.8 -22.4 ...\n $ Solar Radiation (MJ/m2)  : num [1:8760] 0 0 0 0 0 0 0 0 0.01 0.23 ...\n $ Rainfall(mm)             : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ Snowfall (cm)            : num [1:8760] 0 0 0 0 0 0 0 0 0 0 ...\n $ Seasons                  : chr [1:8760] \"Winter\" \"Winter\" \"Winter\" \"Winter\" ...\n $ Holiday                  : chr [1:8760] \"No Holiday\" \"No Holiday\" \"No Holiday\" \"No Holiday\" ...\n $ Functioning Day          : chr [1:8760] \"Yes\" \"Yes\" \"Yes\" \"Yes\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Date = col_character(),\n  ..   `Rented Bike Count` = col_double(),\n  ..   Hour = col_double(),\n  ..   `Temperature(°C)` = col_double(),\n  ..   `Humidity(%)` = col_double(),\n  ..   `Wind speed (m/s)` = col_double(),\n  ..   `Visibility (10m)` = col_double(),\n  ..   `Dew point temperature(°C)` = col_double(),\n  ..   `Solar Radiation (MJ/m2)` = col_double(),\n  ..   `Rainfall(mm)` = col_double(),\n  ..   `Snowfall (cm)` = col_double(),\n  ..   Seasons = col_character(),\n  ..   Holiday = col_character(),\n  ..   `Functioning Day` = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\nOutside of Date being a character instead of a date, and Seasons,Holiday, and Functioning Day being character types instead of factors, things look good! We can address those issues in a bit.\nA tricky variable is Hour, as it is “circular”; hour 23 of one day is only 60 minutes from hour 0 of the next day. We will go ahead and convert this to a factor to be safe.\n\n#Converting Hour to a factor variable\nbike_share_data&lt;-bike_share_data |&gt;\n  mutate(Hour = factor(Hour))\n\nAs additional validity checks, we will explore the values of each variable. To do so, we will generate basic summary statistics for the numeric variables and list the distinct values of the categorical variables.\n\n#Generating basic summary statistics for the numeric variables\nbike_share_data |&gt;\n  summarize(across(where(is.numeric),list(\"mean\" = mean,\n                                     \"median\" = median,\n                                      \"sd\" = sd,\n                                      \"IQR\" = IQR,\n                                      \"min\" = min,\n                                      \"max\" = max),\n                   .names = \"{.fn}__{.col}\")) |&gt;\n  pivot_longer(everything(),names_to = c(\".value\", \"variable\"),names_sep = \"__\") \n\n# A tibble: 9 × 7\n  variable                        mean  median          sd     IQR   min     max\n  &lt;chr&gt;                          &lt;dbl&gt;   &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Rented Bike Count        7.046021e+2  504.5  644.9975     874.25   0   3556   \n2 Temperature(°C)          1.288292e+1   13.7   11.94483     19    -17.8   39.4 \n3 Humidity(%)              5.822626e+1   57     20.36241     32      0     98   \n4 Wind speed (m/s)         1.724909e+0    1.5    1.036300     1.4    0      7.4 \n5 Visibility (10m)         1.436826e+3 1698    608.2987    1060     27   2000   \n6 Dew point temperature(°… 4.073813e+0    5.1   13.06037     19.5  -30.6   27.2 \n7 Solar Radiation (MJ/m2)  5.691107e-1    0.01   0.8687462    0.93   0      3.52\n8 Rainfall(mm)             1.486872e-1    0      1.128193     0      0     35   \n9 Snowfall (cm)            7.506849e-2    0      0.4367462    0      0      8.8 \n\n\nLooking at the summary statistics for the numeric variables, nothing seems particularly concerning. However, I admit that I am not very knowledgeable of the normal range for solar radiation.\nFor the categorical variables, we won’t worry about Date; we will check the range of this variable once we convert is to a date type.\n\n#Listing unique values of the categorical and factor variables excluding Date\nbike_share_data |&gt;\n  select(Hour, Seasons, Holiday, `Functioning Day`) |&gt;\n  map(unique)\n\n$Hour\n [1] 0  1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17 18 19 20 21 22 23\nLevels: 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n\n$Seasons\n[1] \"Winter\" \"Spring\" \"Summer\" \"Autumn\"\n\n$Holiday\n[1] \"No Holiday\" \"Holiday\"   \n\n$`Functioning Day`\n[1] \"Yes\" \"No\" \n\n\nNo concerning values here.\nOnto Date. We need to make this a date type so that it is more easily used. We can use the lubridate package for that.\nAfter making the conversion, we can confirm the conversion worked by looking at the structure and extracting the min and max dates.\n\n#Converting Date to a date\nbike_share_data&lt;-bike_share_data |&gt;\n  mutate(Date = dmy(Date))\n\n#Confirming change\nstr(bike_share_data$Date)\n\n Date[1:8760], format: \"2017-12-01\" \"2017-12-01\" \"2017-12-01\" \"2017-12-01\" \"2017-12-01\" ...\n\n#Extracting min and max\nbike_share_data |&gt;\n  summarize(min = min(Date),max = max(Date))\n\n# A tibble: 1 × 2\n  min        max       \n  &lt;date&gt;     &lt;date&gt;    \n1 2017-12-01 2018-11-30\n\n\nLooking at the structure as well as the endpoints of the date range, everything looks good! It seems we have a year of data starting on December 12, 2017, and ending on November 30, 2018.\nLet’s convert the remaining character types to factors. Given the current values are generally informative, we won’t worry about creating any new labels for the levels.\n\n#Converting character types to factors\nbike_share_data&lt;-bike_share_data |&gt;\n  mutate(across(where(is.character),factor))\n\nBefore we move on to exploring our data more deeply, let’s convert the names to ones that are more R-friendly and consistent.\n\n#Converting to more friendly variable names\nbike_share_data&lt;-bike_share_data |&gt;\n  rename(date = Date,\n         rented_count = `Rented Bike Count`,\n         hour = Hour,\n         temperature = `Temperature(°C)`,\n         humidity = `Humidity(%)`,\n         wind_speed = `Wind speed (m/s)`,\n         visibility = `Visibility (10m)`,\n         dew_point = `Dew point temperature(°C)`,\n         radiation = `Solar Radiation (MJ/m2)`,\n         rainfall = `Rainfall(mm)`,\n         snowfall = `Snowfall (cm)`,\n         season = Seasons,\n         holiday = Holiday,\n         functional = `Functioning Day`)\n\n\n\nSummarizing the Hourly Data\nWe’ve already produced overall summary statistics for our numeric variables. In doing so, we saw that there were roughly 705 bikes rented each hour, on average. We also saw that there was a substantial amount of variation with the standard deviation being nearly as large as the mean (645 bikes).\nNow, let’s generate the same summary statistics for our variable of interest (number of bikes rented) by levels of season, holiday, and functional.\nTo start, we will summarize rental counts across levels of the functioning indicator, as it may reflect the hours the program is and is not operational.\n\n#Generating summary statistics for bikes rented by functional\nbike_share_data |&gt;\n  group_by(functional) |&gt;\n  summarize(across(rented_count,list(\"mean\" = mean,\n                                      \"median\" = median,\n                                      \"sd\" = sd,\n                                      \"IQR\" = IQR,\n                                      \"min\" = min,\n                                      \"max\" = max),\n                   .names = \"{.fn}__{.col}\")) |&gt;\n  pivot_longer(mean__rented_count:max__rented_count,names_to = c(\".value\", \"variable\"),\n               names_sep = \"__\") \n\n# A tibble: 2 × 8\n  functional variable         mean median       sd   IQR   min   max\n  &lt;fct&gt;      &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 No         rented_count   0           0   0          0     0     0\n2 Yes        rented_count 729.1570    542 642.3512   870     2  3556\n\n\nIndeed, there are no rentals for the hours in which functional is “no”. Let’s subset to only observations where this indicator has a value of “yes”.\n\n#Subsetting to only operating hours\nbike_share_data&lt;-bike_share_data |&gt;\n  filter(functional==\"Yes\") |&gt;\n  select(!functional)\n\n\n#Generating summary statistics for bikes rented by season\nbike_share_data |&gt;\n  group_by(season) |&gt;\n  summarize(across(rented_count,list(\"mean\" = mean,\n                                      \"median\" = median,\n                                      \"sd\" = sd,\n                                      \"IQR\" = IQR,\n                                      \"min\" = min,\n                                      \"max\" = max),\n                   .names = \"{.fn}__{.col}\")) |&gt;\n  pivot_longer(mean__rented_count:max__rented_count,names_to = c(\".value\", \"variable\"),\n               names_sep = \"__\") \n\n# A tibble: 4 × 8\n  season variable          mean median       sd    IQR   min   max\n  &lt;fct&gt;  &lt;chr&gt;            &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Autumn rented_count  924.1105  856   617.5479 844        2  3298\n2 Spring rented_count  746.2542  599   618.6680 893        2  3251\n3 Summer rented_count 1034.073   905.5 690.2448 915.75     9  3556\n4 Winter rented_count  225.5412  203   150.3722 195        3   937\n\n\nNote that winter has much lower average hourly rentals. This makes sense as this is the coldest time of the year.\nNow, let’s look at rental rates by the holiday indicator.\n\n#Generating summary statistics for bikes rented by holiday indicator\nbike_share_data |&gt;\n  group_by(holiday) |&gt;\n  summarize(across(rented_count,list(\"mean\" = mean,\n                                      \"median\" = median,\n                                      \"sd\" = sd,\n                                      \"IQR\" = IQR,\n                                      \"min\" = min,\n                                      \"max\" = max),\n                   .names = \"{.fn}__{.col}\")) |&gt;\n  pivot_longer(mean__rented_count:max__rented_count,names_to = c(\".value\", \"variable\"),\n               names_sep = \"__\") \n\n# A tibble: 2 × 8\n  holiday    variable         mean median       sd    IQR   min   max\n  &lt;fct&gt;      &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Holiday    rented_count 529.1544    259 573.9323 694.25     3  2400\n2 No Holiday rented_count 739.2850    561 644.0047 872        2  3556\n\n\nInterestingly, the average hourly rental count is lower on holidays. This may be because holidays are more likely to occur in colder seasons, or it may be because the bikes are commonly used to travel to and from work.\nTo investigate this, let’s look at rental counts by season AND holiday.\n\n#Generating summary statistics for bikes rented by season and holiday indicator\n\nbike_share_data |&gt;\n  group_by(season, holiday) |&gt;\n  summarize(across(rented_count,list(\"mean\" = mean,\n                                      \"median\" = median,\n                                      \"sd\" = sd,\n                                      \"IQR\" = IQR,\n                                      \"min\" = min,\n                                      \"max\" = max),\n                   .names = \"{.fn}__{.col}\")) |&gt;\n  pivot_longer(mean__rented_count:max__rented_count,names_to = c(\".value\", \"variable\"),\n               names_sep = \"__\") \n\n`summarise()` has grouped output by 'season'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 9\n# Groups:   season [4]\n  season holiday    variable          mean median       sd    IQR   min   max\n  &lt;fct&gt;  &lt;fct&gt;      &lt;chr&gt;            &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Autumn Holiday    rented_count  948.1042  900   603.4026 973.25   105  2400\n2 Autumn No Holiday rented_count  922.8593  852   618.4115 833        2  3298\n3 Spring Holiday    rented_count  635.3056  366.5 608.9188 869.5     11  2082\n4 Spring No Holiday rented_count  750.0800  605   618.7902 890.5      2  3251\n5 Summer Holiday    rented_count 1022.146   925   564.3735 848.25   218  2163\n6 Summer No Holiday rented_count 1034.338   904.5 692.8875 918        9  3556\n7 Winter Holiday    rented_count  156.625   138   107.5129 150        3   671\n8 Winter No Holiday rented_count  232.2647  212   152.2752 196.25     7   937\n\n\nIt seems the average hourly rental count is lower on holidays in spring and winter. However, the opposite is true in the fall and the difference is negligible in the summer.\nAs a final step, let’s look at pairwise correlations for the numeric variables.\n\nbike_share_data |&gt;\n  select(where(is.numeric)) |&gt;\n  cor() |&gt;\n  kable(caption=\"Pairwise Correlations for Numeric Variables (Hourly)\") |&gt;\n  kable_styling() |&gt;\n  column_spec(column = 1,bold = TRUE) \n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\nPairwise Correlations for Numeric Variables (Hourly)\n\n\n\nrented_count\ntemperature\nhumidity\nwind_speed\nvisibility\ndew_point\nradiation\nrainfall\nsnowfall\n\n\n\n\nrented_count\n1.0000000\n0.5627402\n-0.2019727\n0.1250219\n0.2123228\n0.4002628\n0.2738616\n-0.1286261\n-0.1516108\n\n\ntemperature\n0.5627402\n1.0000000\n0.1664252\n-0.0384808\n0.0282621\n0.9144670\n0.3548435\n0.0521489\n-0.2177458\n\n\nhumidity\n-0.2019727\n0.1664252\n1.0000000\n-0.3373524\n-0.5485418\n0.5394024\n-0.4572727\n0.2369169\n0.1101265\n\n\nwind_speed\n0.1250219\n-0.0384808\n-0.3373524\n1.0000000\n0.1804276\n-0.1771701\n0.3262219\n-0.0249313\n-0.0037893\n\n\nvisibility\n0.2123228\n0.0282621\n-0.5485418\n0.1804276\n1.0000000\n-0.1825864\n0.1530461\n-0.1703518\n-0.1228597\n\n\ndew_point\n0.4002628\n0.9144670\n0.5394024\n-0.1771701\n-0.1825864\n1.0000000\n0.0985250\n0.1268125\n-0.1497598\n\n\nradiation\n0.2738616\n0.3548435\n-0.4572727\n0.3262219\n0.1530461\n0.0985250\n1.0000000\n-0.0741573\n-0.0733799\n\n\nrainfall\n-0.1286261\n0.0521489\n0.2369169\n-0.0249313\n-0.1703518\n0.1268125\n-0.0741573\n1.0000000\n0.0086041\n\n\nsnowfall\n-0.1516108\n-0.2177458\n0.1101265\n-0.0037893\n-0.1228597\n-0.1497598\n-0.0733799\n0.0086041\n1.0000000\n\n\n\n\n\n\n\nFocusing on correlations with the response, it seems temperature and sunlight (proxied by radiation) have the strongest correlations with rental count. humidity has the weakest relationship with rental count, but there may still be a non-linear relationship or a linear relationship that only exists when we control for other factors correlated with humidity and rented_count.\n\n\nConverting to Daily Data\nTo simplify our analysis, let’s convert our hourly data to daily. In many ways, this is more informative, as intra-day variations add an unnecessary layer of complexity.\nTo do so, we will sum hourly rental counts, snowfall, and rainfall. We will average everything else.\n\n#Converting data to daily\nbike_share_data&lt;-bike_share_data |&gt;\n  group_by(date, season, holiday) |&gt;\n  mutate(across(c(rented_count, snowfall, rainfall),sum,.names = \"{.col}_day\"), #some variables to sums\n         across(temperature:radiation,mean,.names = \"{.col}_day\")) |&gt; #others to means\n  ungroup() |&gt;\n  distinct(date, season, holiday, .keep_all = TRUE) |&gt;\n  select(date, season, holiday, ends_with(\"_day\")) |&gt; #removing original hourly numeric variables\n  rename_with(~ str_remove(.,\"_day\"))\n\n\n\nSummarizing the Daily Data\nNow that we have daily data, let’s recreate the summary statistics we produced for the hourly data.\nTo start, let’s reproduce the overall summary statistics for our numeric variables.\n\n#Generating basic summary statistics for the numeric variables\nbike_share_data |&gt;\n  summarize(across(where(is.numeric),list(\"mean\" = mean,\n                                     \"median\" = median,\n                                      \"sd\" = sd,\n                                      \"IQR\" = IQR,\n                                      \"min\" = min,\n                                      \"max\" = max),\n                   .names = \"{.fn}__{.col}\")) |&gt;\n  pivot_longer(everything(),names_to = c(\".value\", \"variable\"),names_sep = \"__\") \n\n# A tibble: 9 × 7\n  variable              mean       median           sd          IQR          min\n  &lt;chr&gt;                &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1 rented_count 17485.31      18563        9937.165      1.9318  e+4 977         \n2 snowfall         1.862890      0           8.804413   0             0         \n3 rainfall         3.575921      0          11.78987    5       e-1   0         \n4 temperature     12.77584      13.7375     11.71840    1.92875 e+1 -14.7375    \n5 humidity        58.16627      57.16667    14.86552    2.0125  e+1  22.25      \n6 wind_speed       1.726148      1.658333    0.5972809  6.5     e-1   0.6625    \n7 visibility    1434.014      1557.75      491.1561     7.8725  e+2 214.2917    \n8 dew_point        3.954165      4.6125     12.99294    2.010833e+1 -27.75      \n9 radiation        0.5677319     0.565       0.3161252  5.366667e-1   0.02916667\n# ℹ 1 more variable: max &lt;dbl&gt;\n\n\nThis clearly demonstrates our transformations, as the previously hourly averages for rented_count, snowfall, and rainfall have now been effectively scaled up to reflect the 24-hour period.\nNow to the arguably more interesting tables, let’s look at the bike rental counts by season.\n\n#Generating summary statistics for bikes rented by season\nbike_share_data |&gt;\n  group_by(season) |&gt;\n  summarize(across(rented_count,list(\"mean\" = mean,\n                                      \"median\" = median,\n                                      \"sd\" = sd,\n                                      \"IQR\" = IQR,\n                                      \"min\" = min,\n                                      \"max\" = max),\n                   .names = \"{.fn}__{.col}\")) |&gt;\n  pivot_longer(mean__rented_count:max__rented_count,names_to = c(\".value\", \"variable\"),\n               names_sep = \"__\") \n\n# A tibble: 4 × 8\n  season variable          mean  median       sd      IQR   min   max\n  &lt;fct&gt;  &lt;chr&gt;            &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Autumn rented_count 22098.79  23350   6710.893 10733     1721 31809\n2 Spring rented_count 17910.1   17590   8357.149 14361.75   977 31681\n3 Summer rented_count 24817.76  25571.5 7297.344  9308.5   3231 36149\n4 Winter rented_count  5412.989  5498   1808.340  2633.75  2014  9539\n\n\nWe see the same pattern as we did for the hourly data, with summer and autumn having the highest daily average counts. One interesting note we did not discuss previously: the standard deviation, inner quartile range, and range all indicate that spring sees the greatest volatility in bike share activity across days. This is not particularly surprising as spring likely has both cold, snowy days and warm, sunny days.\nLet’s look again at rental activity by the holiday indicator.\n\n#Generating summary statistics for bikes rented by holiday indicator\nbike_share_data |&gt;\n  group_by(holiday) |&gt;\n  summarize(across(rented_count,list(\"mean\" = mean,\n                                      \"median\" = median,\n                                      \"sd\" = sd,\n                                      \"IQR\" = IQR,\n                                      \"min\" = min,\n                                      \"max\" = max),\n                   .names = \"{.fn}__{.col}\")) |&gt;\n  pivot_longer(mean__rented_count:max__rented_count,names_to = c(\".value\", \"variable\"),\n               names_sep = \"__\") \n\n# A tibble: 2 × 8\n  holiday    variable         mean  median        sd      IQR   min   max\n  &lt;fct&gt;      &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Holiday    rented_count 12699.71  7184   10504.34  16576     2014 30498\n2 No Holiday rented_count 17727.44 19104.5  9862.417 19167.75   977 36149\n\n\nWe again see the intriguing factor that non-holiday days in our sample see greater rental activity, on average.\nAs we did previously, we will explore whether this relationship holds across seasons.\n\n#Generating summary statistics for bikes rented by season and holiday indicator\n\nbike_share_data |&gt;\n  group_by(season, holiday) |&gt;\n  summarize(across(rented_count,list(\"mean\" = mean,\n                                      \"median\" = median,\n                                      \"sd\" = sd,\n                                      \"IQR\" = IQR,\n                                      \"min\" = min,\n                                      \"max\" = max),\n                   .names = \"{.fn}__{.col}\")) |&gt;\n  pivot_longer(mean__rented_count:max__rented_count,names_to = c(\".value\", \"variable\"),\n               names_sep = \"__\") \n\n`summarise()` has grouped output by 'season'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 8 × 9\n# Groups:   season [4]\n  season holiday    variable         mean  median        sd      IQR   min   max\n  &lt;fct&gt;  &lt;fct&gt;      &lt;chr&gt;           &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Autumn Holiday    rented_cou… 22754.5   21705    5641.864  5740    17259 30349\n2 Autumn No Holiday rented_cou… 22064.73  23472    6791.622 10734     1721 31809\n3 Spring Holiday    rented_cou… 15247.33  13790   10917.20  10844     5132 26820\n4 Spring No Holiday rented_cou… 18001.92  17730    8321.699 14223.5    977 31681\n5 Summer Holiday    rented_cou… 24531.5   24531.5  8437.905  5966.5  18565 30498\n6 Summer No Holiday rented_cou… 24824.12  25571.5  7324.345  9165     3231 36149\n7 Winter Holiday    rented_cou…  3759      3453.5  1561.108  1060.25  2014  7184\n8 Winter No Holiday rented_cou…  5574.354  5609    1756.674  2564     2487  9539\n\n\nWe again see that non-holiday days see more activity, on average, than holiday days only in spring and winter.\nBefore we produce graphical summaries of the data, let’s reproduce the pairwise correlation table.\n\nbike_share_data |&gt;\n  select(where(is.numeric)) |&gt;\n  cor() |&gt;\n  kable(caption=\"Pairwise Correlations for Numeric Variables (Daily)\") |&gt;\n  kable_styling() |&gt;\n  column_spec(column = 1,bold = TRUE) \n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\nPairwise Correlations for Numeric Variables (Daily)\n\n\n\nrented_count\nsnowfall\nrainfall\ntemperature\nhumidity\nwind_speed\nvisibility\ndew_point\nradiation\n\n\n\n\nrented_count\n1.0000000\n-0.2652911\n-0.2391091\n0.7530767\n0.0358870\n-0.1928814\n0.1659937\n0.6504765\n0.7358929\n\n\nsnowfall\n-0.2652911\n1.0000000\n-0.0231340\n-0.2669637\n0.0653919\n0.0208816\n-0.1018890\n-0.2095529\n-0.2334306\n\n\nrainfall\n-0.2391091\n-0.0231340\n1.0000000\n0.1445173\n0.5286426\n-0.1016758\n-0.2219939\n0.2645662\n-0.3227041\n\n\ntemperature\n0.7530767\n-0.2669637\n0.1445173\n1.0000000\n0.4041675\n-0.2607218\n0.0023367\n0.9627963\n0.5502743\n\n\nhumidity\n0.0358870\n0.0653919\n0.5286426\n0.4041675\n1.0000000\n-0.2342578\n-0.5591773\n0.6320473\n-0.2744497\n\n\nwind_speed\n-0.1928814\n0.0208816\n-0.1016758\n-0.2607218\n-0.2342578\n1.0000000\n0.2060226\n-0.2877032\n0.0961263\n\n\nvisibility\n0.1659937\n-0.1018890\n-0.2219939\n0.0023367\n-0.5591773\n0.2060226\n1.0000000\n-0.1535516\n0.2713959\n\n\ndew_point\n0.6504765\n-0.2095529\n0.2645662\n0.9627963\n0.6320473\n-0.2877032\n-0.1535516\n1.0000000\n0.3831571\n\n\nradiation\n0.7358929\n-0.2334306\n-0.3227041\n0.5502743\n-0.2744497\n0.0961263\n0.2713959\n0.3831571\n1.0000000\n\n\n\n\n\n\n\nThere are no major differences between the daily and hourly correlations.\nLet’s now look at scatterplots that visually compare our response to each numeric predictor.\n\nplot_list&lt;-list()\n\nfor (v in names(bike_share_data)[5:12]) {\n  g&lt;-ggplot(data=bike_share_data,aes(x = !!sym(v),y = rented_count)) + geom_point() + \n    labs(y = \"Rented Bikes\")\n  plot_list&lt;-c(plot_list,g) \n}\n\nwrap_plots(plot_list) + plot_annotation(title = \"Daily Bike Rentals vs. Each Numeric Predictor\")\n\n\n\n\n\n\n\n\nOne thing stands out that was reflected in the overall summary statistics table: the majority of days have no rain and/or no snow.\nOverall, there are no clear signs of any non-linear relationships that would have been overlooked if we only considered correlations.\nIf we were focused on inference, the fanning of rented bikes counts as dew point and temperature increased would be of concern because of the constant variance assumption for linear regression models. Fortunately, we are focused on prediction.\n\n\n\nSplitting the Data\nTo evaluate the predictive capabilities of the multiple linear regression models we build, we need to split the data into training and test sets. Let’s retain 75% of the data for training and stratify by season to ensure the seasonal breakdowns are similar across training and test sets.\n\n#Setting seed for reproducibility\nset.seed(10)\n\n#Splitting the data into training and test sets \nbike_share_split&lt;-initial_split(bike_share_data, strata = season, prop = 0.75)\n\n#Printing the structure of the split object\nbike_share_split\n\n&lt;Training/Testing/Total&gt;\n&lt;263/90/353&gt;\n\n\nNote that in printing the structure we see that 263 of the 353 day-level observations are retained in the training set; the other 90 observations are places in the test set.\nLet’s extract the training and test sets for use in our analysis. Let’s also split the training set into 10 folds so that we can identify the best model among candidate linear regression models using 10-fold cross validation.\n\n#Setting seed for reproducibility \nset.seed(5)\n\n#Extracting training and test sets\nbike_share_train&lt;-training(bike_share_split)\nbike_share_test&lt;-testing(bike_share_split)\n\n#Separating the training data into the 10 folds\nfolds&lt;-vfold_cv(bike_share_train, v = 10)\n\n#Printing the structure of the folds object\nfolds\n\n#  10-fold cross-validation \n# A tibble: 10 × 2\n   splits           id    \n   &lt;list&gt;           &lt;chr&gt; \n 1 &lt;split [236/27]&gt; Fold01\n 2 &lt;split [236/27]&gt; Fold02\n 3 &lt;split [236/27]&gt; Fold03\n 4 &lt;split [237/26]&gt; Fold04\n 5 &lt;split [237/26]&gt; Fold05\n 6 &lt;split [237/26]&gt; Fold06\n 7 &lt;split [237/26]&gt; Fold07\n 8 &lt;split [237/26]&gt; Fold08\n 9 &lt;split [237/26]&gt; Fold09\n10 &lt;split [237/26]&gt; Fold10\n\n\nIn printing folds, we see that we have segmented the training data into 10 folds.\n\n\nModeling Rental Counts with Multiple Linear Regression Models\nNow we can build some models. The first model we will specify has the following characteristics:\n\nAll variables in the dataset are used to predict rented_count\n\nThe one caveat is that we use a weekend indicator rather than date explicitly\n\nAll numeric variables are normalized\nDummies are creates for the levels of the factor variables (season, holiday, and the new weekend indicator)\n\n\n#Constructing first recipe\nbike_rec_1&lt;-recipe(rented_count ~ ., data = bike_share_train) |&gt;\n  #Assigning date to ID role\n  update_role(date, new_role = \"ID\") |&gt;\n  #Creating intermediate day-of-week variable\n  step_date(date, features = c(\"dow\")) |&gt;\n  #Creating weekend indicator\n  step_mutate(weekend = factor(if_else(date_dow %in% c(\"Sat\",\"Sun\"),\"yes\",\"no\"))) |&gt;\n  #Removing intermediate variable\n  step_rm(date_dow) |&gt;\n  #Normalizing all numeric predictors\n  step_normalize(all_numeric(), -all_outcomes()) |&gt;\n  #Creating dummies for all factors\n  step_dummy(season, holiday, weekend)\n\n#Printing recipe variable list with roles\nbike_rec_1 |&gt;\n  prep(training = bike_share_train) |&gt;\n  summary()\n\n# A tibble: 15 × 4\n   variable           type      role      source  \n   &lt;chr&gt;              &lt;list&gt;    &lt;chr&gt;     &lt;chr&gt;   \n 1 date               &lt;chr [1]&gt; ID        original\n 2 snowfall           &lt;chr [2]&gt; predictor original\n 3 rainfall           &lt;chr [2]&gt; predictor original\n 4 temperature        &lt;chr [2]&gt; predictor original\n 5 humidity           &lt;chr [2]&gt; predictor original\n 6 wind_speed         &lt;chr [2]&gt; predictor original\n 7 visibility         &lt;chr [2]&gt; predictor original\n 8 dew_point          &lt;chr [2]&gt; predictor original\n 9 radiation          &lt;chr [2]&gt; predictor original\n10 rented_count       &lt;chr [2]&gt; outcome   original\n11 season_Spring      &lt;chr [2]&gt; predictor derived \n12 season_Summer      &lt;chr [2]&gt; predictor derived \n13 season_Winter      &lt;chr [2]&gt; predictor derived \n14 holiday_No.Holiday &lt;chr [2]&gt; predictor derived \n15 weekend_yes        &lt;chr [2]&gt; predictor derived \n\n\nIn printing the summary of the prepped recipe, we can see that date now has the role “ID” rather than “predictor”. We can also see the indicators that were created.\nLet’s specify a second model that includes all the previous characteristics, but also includes interactions for season and holiday, season and temperature, and temperature and rainfall.\n\n#Constructing first recipe\nbike_rec_2&lt;-recipe(rented_count ~ ., data = bike_share_train) |&gt;\n  #Assigning date to ID role\n  update_role(date, new_role = \"ID\") |&gt;\n  #Creating intermediate day-of-week variable\n  step_date(date, features=c(\"dow\")) |&gt;\n  #Creating weekend indicator\n  step_mutate(weekend = factor(if_else(date_dow %in% c(\"Sat\",\"Sun\"),\"yes\",\"no\"))) |&gt;\n  #Removing intermediate variable\n  step_rm(date_dow) |&gt;\n  #Normalizing all numeric predictors\n  step_normalize(all_numeric(), -all_outcomes()) |&gt;\n  #Creating dummies for all factors\n  step_dummy(season, holiday, weekend) |&gt;\n  #Adding season-holiday interaction\n  step_interact(terms = ~holiday_No.Holiday*starts_with(\"season\")) |&gt;\n  #Adding season-temp interaction \n  step_interact(terms = ~temperature*starts_with(\"season\")) |&gt;\n  #Adding temperature-rainfall interaction \n  step_interact(terms = ~temperature*rainfall)\n  \n\n#Printing recipe variable list with roles\nbike_rec_2 |&gt;\n  prep(training = bike_share_train) |&gt;\n  summary() |&gt;\n  print(n = 22)\n\n# A tibble: 22 × 4\n   variable                           type      role      source  \n   &lt;chr&gt;                              &lt;list&gt;    &lt;chr&gt;     &lt;chr&gt;   \n 1 date                               &lt;chr [1]&gt; ID        original\n 2 snowfall                           &lt;chr [2]&gt; predictor original\n 3 rainfall                           &lt;chr [2]&gt; predictor original\n 4 temperature                        &lt;chr [2]&gt; predictor original\n 5 humidity                           &lt;chr [2]&gt; predictor original\n 6 wind_speed                         &lt;chr [2]&gt; predictor original\n 7 visibility                         &lt;chr [2]&gt; predictor original\n 8 dew_point                          &lt;chr [2]&gt; predictor original\n 9 radiation                          &lt;chr [2]&gt; predictor original\n10 rented_count                       &lt;chr [2]&gt; outcome   original\n11 season_Spring                      &lt;chr [2]&gt; predictor derived \n12 season_Summer                      &lt;chr [2]&gt; predictor derived \n13 season_Winter                      &lt;chr [2]&gt; predictor derived \n14 holiday_No.Holiday                 &lt;chr [2]&gt; predictor derived \n15 weekend_yes                        &lt;chr [2]&gt; predictor derived \n16 holiday_No.Holiday_x_season_Spring &lt;chr [2]&gt; predictor derived \n17 holiday_No.Holiday_x_season_Summer &lt;chr [2]&gt; predictor derived \n18 holiday_No.Holiday_x_season_Winter &lt;chr [2]&gt; predictor derived \n19 temperature_x_season_Spring        &lt;chr [2]&gt; predictor derived \n20 temperature_x_season_Summer        &lt;chr [2]&gt; predictor derived \n21 temperature_x_season_Winter        &lt;chr [2]&gt; predictor derived \n22 temperature_x_rainfall             &lt;chr [2]&gt; predictor derived \n\n\nWhen printing the summary of this prepped recipe, we see the interaction terms; the “x” in the interaction term names is a nice touch by the tidyverse.\nLet’s specify a final model, which includes all of the characteristics as the second model and also includes quadratic terms for the numeric predictors.\n\n#Constructing first recipe\nbike_rec_3&lt;-recipe(rented_count ~ ., data = bike_share_train) |&gt;\n  #Assigning date to ID role\n  update_role(date, new_role = \"ID\") |&gt;\n  #Creating intermediate day-of-week variable\n  step_date(date, features=c(\"dow\")) |&gt;\n  #Creating weekend indicator\n  step_mutate(weekend = factor(if_else(date_dow %in% c(\"Sat\",\"Sun\"),\"yes\",\"no\"))) |&gt;\n  #Removing intermediate variable\n  step_rm(date_dow) |&gt;\n  #Normalizing all numeric predictors\n  step_normalize(all_numeric(), -all_outcomes()) |&gt;\n  #Adding quadratic terms for numeric variables\n  step_poly(all_numeric(), -all_outcomes(), degree = 2, options = list(raw = TRUE)) |&gt; \n  #Creating dummies for all factors\n  step_dummy(season, holiday, weekend) |&gt;\n  #Adding season-holiday interaction\n  step_interact(terms = ~holiday_No.Holiday*starts_with(\"season\")) |&gt;\n  #Adding season-temp interaction \n  step_interact(terms = ~temperature_poly_1*starts_with(\"season\")) |&gt;\n  #Adding temperature-rainfall interaction \n  step_interact(terms = ~temperature_poly_1*rainfall_poly_1)\n  \n\n#Printing recipe variable list with roles\nbike_rec_3 |&gt;\n  prep(training = bike_share_train) |&gt;\n  summary() |&gt;\n  print(n = 30)\n\n# A tibble: 30 × 4\n   variable                             type      role      source  \n   &lt;chr&gt;                                &lt;list&gt;    &lt;chr&gt;     &lt;chr&gt;   \n 1 date                                 &lt;chr [1]&gt; ID        original\n 2 rented_count                         &lt;chr [2]&gt; outcome   original\n 3 snowfall_poly_1                      &lt;chr [2]&gt; predictor derived \n 4 snowfall_poly_2                      &lt;chr [2]&gt; predictor derived \n 5 rainfall_poly_1                      &lt;chr [2]&gt; predictor derived \n 6 rainfall_poly_2                      &lt;chr [2]&gt; predictor derived \n 7 temperature_poly_1                   &lt;chr [2]&gt; predictor derived \n 8 temperature_poly_2                   &lt;chr [2]&gt; predictor derived \n 9 humidity_poly_1                      &lt;chr [2]&gt; predictor derived \n10 humidity_poly_2                      &lt;chr [2]&gt; predictor derived \n11 wind_speed_poly_1                    &lt;chr [2]&gt; predictor derived \n12 wind_speed_poly_2                    &lt;chr [2]&gt; predictor derived \n13 visibility_poly_1                    &lt;chr [2]&gt; predictor derived \n14 visibility_poly_2                    &lt;chr [2]&gt; predictor derived \n15 dew_point_poly_1                     &lt;chr [2]&gt; predictor derived \n16 dew_point_poly_2                     &lt;chr [2]&gt; predictor derived \n17 radiation_poly_1                     &lt;chr [2]&gt; predictor derived \n18 radiation_poly_2                     &lt;chr [2]&gt; predictor derived \n19 season_Spring                        &lt;chr [2]&gt; predictor derived \n20 season_Summer                        &lt;chr [2]&gt; predictor derived \n21 season_Winter                        &lt;chr [2]&gt; predictor derived \n22 holiday_No.Holiday                   &lt;chr [2]&gt; predictor derived \n23 weekend_yes                          &lt;chr [2]&gt; predictor derived \n24 holiday_No.Holiday_x_season_Spring   &lt;chr [2]&gt; predictor derived \n25 holiday_No.Holiday_x_season_Summer   &lt;chr [2]&gt; predictor derived \n26 holiday_No.Holiday_x_season_Winter   &lt;chr [2]&gt; predictor derived \n27 temperature_poly_1_x_season_Spring   &lt;chr [2]&gt; predictor derived \n28 temperature_poly_1_x_season_Summer   &lt;chr [2]&gt; predictor derived \n29 temperature_poly_1_x_season_Winter   &lt;chr [2]&gt; predictor derived \n30 temperature_poly_1_x_rainfall_poly_1 &lt;chr [2]&gt; predictor derived \n\n\nWe now have quadratic terms; note that the original numeric variables now have a “_poly_1” suffix to explicitly indicate they are still linear terms.\nOur next step is to specify the type of model we want to fit, which is the linear regression model.\n\n#Specifying an ordinary least squares model\nlm_model&lt;-linear_reg() |&gt;\n  set_engine(\"lm\")\n\nIt is finally time to fit some models and see how well they predict! The code below fits each of the three models we have specified above for each of the 10 “training” sets and collects their cross-validated prediction error metrics.\n\n#Fitting first model to each \"training\" set and testing for each fold \nbike_fit_1&lt;-workflow() |&gt;\n  add_recipe(bike_rec_1) |&gt;\n  add_model(lm_model) |&gt;\n  fit_resamples(folds)\n\n#Fitting second model to each \"training\" set and testing for each fold \nbike_fit_2&lt;-workflow() |&gt;\n  add_recipe(bike_rec_2) |&gt;\n  add_model(lm_model) |&gt;\n  fit_resamples(folds)\n\n#Fitting third model to each \"training\" set and testing for each fold \nbike_fit_3&lt;-workflow() |&gt;\n  add_recipe(bike_rec_3) |&gt;\n  add_model(lm_model) |&gt;\n  fit_resamples(folds)\n\n#Capturing fit metrics\nrbind(bike_fit_1 |&gt; collect_metrics() |&gt; mutate(model = 1) |&gt; select(model, everything()),\n      bike_fit_2 |&gt; collect_metrics() |&gt; mutate(model = 2) |&gt; select(model, everything()),\n      bike_fit_3 |&gt; collect_metrics() |&gt; mutate(model = 3) |&gt; select(model, everything()))\n\n# A tibble: 6 × 7\n  model .metric .estimator         mean     n      std_err .config        \n  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;             &lt;dbl&gt; &lt;int&gt;        &lt;dbl&gt; &lt;chr&gt;          \n1     1 rmse    standard   4332.653        10  85.44616    pre0_mod0_post0\n2     1 rsq     standard      0.8179826    10   0.01132838 pre0_mod0_post0\n3     2 rmse    standard   3122.705        10 264.9047     pre0_mod0_post0\n4     2 rsq     standard      0.9023865    10   0.01767856 pre0_mod0_post0\n5     3 rmse    standard   3069.269        10 280.0173     pre0_mod0_post0\n6     3 rsq     standard      0.9042805    10   0.01850216 pre0_mod0_post0\n\n\nBased on the cross-validated “test” root mean squared error (RMSE), the third linear regression model predicts the number of rented bikes best.\nNow that we’ve identified the best model, let’s fit the model to the entire training set and obtain a final estimate of the out-of-sample RMSE using the original test set.\n\n#Fitting model to full training set and testing on full test set\nfinal_fit&lt;-workflow() |&gt;\n  add_recipe(bike_rec_3) |&gt;\n  add_model(lm_model) |&gt;\n  last_fit(bike_share_split, metrics = metric_set(rmse, mae))\n\n#Extracting predictive performance for test set\nfinal_fit |&gt; collect_metrics()\n\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config        \n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n1 rmse    standard    2963.439 pre0_mod0_post0\n2 mae     standard    2181.411 pre0_mod0_post0\n\n\nAs we would expect, the test RMSE is similar to that of the cross-validated RMSE we previously obtained for this model. In fact, the RMSE is slightly lower here, which could be explained by the fact that we used the full training set to train this model or simply by randomness.\nAs a final step, let’s extract a summary of the model fit.\n\n#Extracting fit summary\nfinal_fit |&gt;\n  extract_fit_parsnip() |&gt;\n  tidy() |&gt;\n  kable()\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\n\n\n\n\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n\n(Intercept)\n18209.37765\n1508.76688\n12.0690465\n0.0000000\n\n\nsnowfall_poly_1\n-117.68556\n618.59272\n-0.1902472\n0.8492803\n\n\nsnowfall_poly_2\n-21.61766\n96.65746\n-0.2236522\n0.8232230\n\n\nrainfall_poly_1\n-2395.91686\n553.78090\n-4.3264708\n0.0000225\n\n\nrainfall_poly_2\n190.90294\n79.76025\n2.3934597\n0.0174793\n\n\ntemperature_poly_1\n1785.73905\n4041.27237\n0.4418755\n0.6589874\n\n\ntemperature_poly_2\n-1133.56024\n1104.11783\n-1.0266660\n0.3056379\n\n\nhumidity_poly_1\n-1564.62701\n1448.20597\n-1.0803898\n0.2810809\n\n\nhumidity_poly_2\n-292.73851\n300.46992\n-0.9742689\n0.3309291\n\n\nwind_speed_poly_1\n-621.07193\n259.94867\n-2.3892099\n0.0176778\n\n\nwind_speed_poly_2\n165.06296\n127.65542\n1.2930353\n0.1972740\n\n\nvisibility_poly_1\n334.28976\n303.56435\n1.1012155\n0.2719343\n\n\nvisibility_poly_2\n-120.67233\n214.16845\n-0.5634458\n0.5736709\n\n\ndew_point_poly_1\n4261.53746\n4648.35411\n0.9167842\n0.3601996\n\n\ndew_point_poly_2\n-313.49257\n729.94508\n-0.4294742\n0.6679733\n\n\nradiation_poly_1\n2837.25189\n382.74822\n7.4128416\n0.0000000\n\n\nradiation_poly_2\n-629.22217\n234.85741\n-2.6791668\n0.0079045\n\n\nseason_Spring\n-2633.38731\n2599.25387\n-1.0131320\n0.3120435\n\n\nseason_Summer\n18967.91348\n3170.71942\n5.9822113\n0.0000000\n\n\nseason_Winter\n-7288.67111\n2815.88995\n-2.5884077\n0.0102457\n\n\nholiday_No.Holiday\n5549.79451\n1497.30154\n3.7065310\n0.0002623\n\n\nweekend_yes\n-2492.73551\n397.78252\n-6.2665789\n0.0000000\n\n\nholiday_No.Holiday_x_season_Spring\n-1366.74899\n2662.05569\n-0.5134186\n0.6081429\n\n\nholiday_No.Holiday_x_season_Summer\n-1661.95577\n2502.46204\n-0.6641283\n0.5072621\n\n\nholiday_No.Holiday_x_season_Winter\n-3848.82785\n1900.37832\n-2.0252956\n0.0439724\n\n\ntemperature_poly_1_x_season_Spring\n5895.06124\n1075.17730\n5.4828736\n0.0000001\n\n\ntemperature_poly_1_x_season_Summer\n-16875.80766\n2431.62763\n-6.9401283\n0.0000000\n\n\ntemperature_poly_1_x_season_Winter\n-5216.36619\n2903.64863\n-1.7964867\n0.0737069\n\n\ntemperature_poly_1_x_rainfall_poly_1\n-1679.91534\n445.97450\n-3.7668417\n0.0002092\n\n\n\n\n\nAs we have not fully evaluated all of the assumptions underlying the p-values, we must be cautious in drawing any inferential conclusions for any of the coefficients. Additionally, the complex non-linear relationships modeled here make interpretation difficult. Acknowledging these limitations, there are still interesting relationships revealed by the coefficients and their p-values. For example, the effect of increasing temperature varies substantially by season, as we see that an increase in temperatures has a uniquely large negative impact on rental activity in the summer. This makes sense, as the average temperature in summer will already be warm and increases of a few degrees Celsius (or a few standard deviations in the model) could correspond to an uncomfortably hot day.\nAdditionally, higher levels of radiation (more sunny day) generally correspond to more rental activity, but there are diminishing returns to increased radiation reflected in the negative quadratic term.\n\n\nEvaluating Additional Models\nLet’s explore the potential of the LASSO model, regression tree model, bagged tree model, and random forest model to predict daily bike rentals.\nTo do so, we will compare predictive performance using the same predictors as above, but not including any interactions or quadratic terms; these terms are not necessary for the tree-based models due to their more flexible nature.\n\nLASSO Model\nWe will start by tuning a LASSO model. Note that we can use the first recipe above and simply add a new model/engine when tuning. Let’s specify the new model/engine.\n\n#Specifying a LASSO model with the penalty parameter tuned\nlasso_model&lt;-linear_reg(penalty = tune(), mixture = 1) |&gt;\n  set_engine(\"glmnet\", standardize = FALSE)\n\n#Specifying workflow\nlasso_wkf&lt;-workflow() |&gt;\n  add_recipe(bike_rec_1) |&gt;\n  add_model(lasso_model)\n\nNow let’s use the same 10 folds as above to determine the “best” value of the penalty parameter.\n\n#Fitting LASSO model for each of 100 penalty values\nlasso_fit&lt;-lasso_wkf |&gt;\n  tune_grid(resamples = folds,\n            grid = grid_regular(penalty(c(-10,2)), levels = 100),\n            metrics = metric_set(rmse)) \n\nThe chunk below extracts cross-validated RMSE values for each lambda/penalty value.\n\n#Extracting fit metrics\nlasso_fit |&gt; collect_metrics() |&gt;\n  arrange(mean)\n\n# A tibble: 100 × 7\n        penalty .metric .estimator     mean     n  std_err .config          \n          &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;            \n 1 1       e-10 rmse    standard   4326.752    10 86.37435 pre0_mod001_post0\n 2 1.321941e-10 rmse    standard   4326.752    10 86.37435 pre0_mod002_post0\n 3 1.747528e-10 rmse    standard   4326.752    10 86.37435 pre0_mod003_post0\n 4 2.310130e-10 rmse    standard   4326.752    10 86.37435 pre0_mod004_post0\n 5 3.053856e-10 rmse    standard   4326.752    10 86.37435 pre0_mod005_post0\n 6 4.037017e-10 rmse    standard   4326.752    10 86.37435 pre0_mod006_post0\n 7 5.336699e-10 rmse    standard   4326.752    10 86.37435 pre0_mod007_post0\n 8 7.054802e-10 rmse    standard   4326.752    10 86.37435 pre0_mod008_post0\n 9 9.326033e-10 rmse    standard   4326.752    10 86.37435 pre0_mod009_post0\n10 1.232847e- 9 rmse    standard   4326.752    10 86.37435 pre0_mod010_post0\n# ℹ 90 more rows\n\n\nNote that the RMSE values are constant until the penalty is above 3.51. This reflects an issue with the way tidymodels calls glmnet(). In particular, tidymodels allows glmnet() to specify its own sequence of penalty values and then interpolates predictions based on those penalty values to obtain predictions for the penalty values we specify. In this case, the lowest value glmnet() tries is a penalty values around 3.51.\nThe code below captures the value of penalty that corresponds to the most conservative model with the best RMSE (penalty=3.51).\n\n#Capturing best LASSO model (least complex \"best\" model)\nlasso_best_params&lt;-show_best(lasso_fit, metric = \"rmse\", n = Inf) |&gt;\n  filter(mean==min(mean)) |&gt;\n  slice_max(penalty) |&gt;\n  select(penalty)\n\n\n\n#Printing hyperparameter value\nlasso_best_params\n\n# A tibble: 1 × 1\n   penalty\n     &lt;dbl&gt;\n1 3.511192\n\n\nWe now have the information we need to evaluate our tuned LASSO model on the test set.\n\n\nRegression Tree\nNow let’s tune a regression tree model to see how well it performs. As we did for the LASSO model, we will start by specifying the model and engine.\n\n#Specifying model and engine for regression tree\ntree_model&lt;-decision_tree(tree_depth = tune(),\n                          min_n = 5,\n                          cost_complexity = tune()) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"regression\")\n\n#Creating regression tree workflow\ntree_wkf&lt;-workflow() |&gt;\n  add_recipe(bike_rec_1) |&gt;\n  add_model(tree_model)\n\nWe are using cross-validation to tune the tree depth and cost complexity hyperparameters, and we are specifying that no endpoint of the tree can have fewer than 5 observations.\nLet’s fit the model across a grid of tree depth and cost complexity values to see which has the best fit characteristics.\n\n#Fitting regression tree model across grid of depth and complexity values\ntree_fit&lt;-tree_wkf |&gt;\n  tune_grid(resamples = folds,\n            grid = grid_regular(tree_depth(), cost_complexity(), levels = c(10,10)),\n            metrics = metric_set(rmse)) \n\nNow that we’ve fit the \\(10x10=100\\) regression tree models, let’s see which has the lowest RMSE.\n\n#Sorting models by RMSE\ntree_fit |&gt; collect_metrics() |&gt;\n  arrange(mean)\n\n# A tibble: 100 × 8\n   cost_complexity tree_depth .metric .estimator     mean     n  std_err .config\n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;  \n 1    0.0001                5 rmse    standard   4092.537    10 162.6993 pre0_m…\n 2    0.0000000001          5 rmse    standard   4093.023    10 162.6976 pre0_m…\n 3    0.000000001           5 rmse    standard   4093.023    10 162.6976 pre0_m…\n 4    0.00000001            5 rmse    standard   4093.023    10 162.6976 pre0_m…\n 5    0.0000001             5 rmse    standard   4093.023    10 162.6976 pre0_m…\n 6    0.000001              5 rmse    standard   4093.023    10 162.6976 pre0_m…\n 7    0.00001               5 rmse    standard   4093.023    10 162.6976 pre0_m…\n 8    0.0001                7 rmse    standard   4115.322    10 212.5100 pre0_m…\n 9    0.00001               7 rmse    standard   4121.130    10 213.6370 pre0_m…\n10    0.0000000001          7 rmse    standard   4121.772    10 213.7138 pre0_m…\n# ℹ 90 more rows\n\n\nLet’s capture the model with the lowest RMSE to test against the best models for the other families.\n\n#Capturing best tree model\ntree_best_params&lt;-select_best(tree_fit, metric = \"rmse\")\n\n#Printing hyperparameter values\ntree_best_params\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config          \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;            \n1          0.0001          5 pre0_mod064_post0\n\n\nOur best model has a tree depth of 5 and cost complexity of 0.0001.\n\n\nBagged Tree\nOnto the bagged tree. Let’s specify our model and engine, indicating that we will again tune tree depth and cost complexity.\n\n#Specifying model and engine for bagged tree\nbag_model&lt;-bag_tree(tree_depth = tune(),\n                          min_n = 5,\n                          cost_complexity = tune()) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"regression\")\n\n#Creating bagged tree workflow\nbag_wkf&lt;-workflow() |&gt;\n  add_recipe(bike_rec_1) |&gt;\n  add_model(bag_model)\n\nLet’s fit our models to each set of “training” and “testing” data corresponding to each fold.\n\n#Setting seed for reproducibility when rerunning chunk\nset.seed(10)\n\n#Fitting bagged tree model across grid of depth and complexity values\nbag_fit&lt;-bag_wkf |&gt;\n  tune_grid(resamples = folds,\n            grid = grid_regular(tree_depth(), cost_complexity(), levels = c(10,10)),\n            metrics = metric_set(rmse)) \n\nNow that we have fit the models, let’s see which has the best cross-validated RMSE.\n\n#Sorting models by RMSE\nbag_fit |&gt; collect_metrics() |&gt;\n  arrange(mean)\n\n# A tibble: 100 × 8\n   cost_complexity tree_depth .metric .estimator     mean     n  std_err .config\n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;  \n 1    0.00000001           13 rmse    standard   2903.273    10 123.0814 pre0_m…\n 2    0.0000000001         10 rmse    standard   2905.642    10 111.4533 pre0_m…\n 3    0.0000001            11 rmse    standard   2911.194    10 149.7095 pre0_m…\n 4    0.00001               7 rmse    standard   2915.458    10 151.7954 pre0_m…\n 5    0.000000001          10 rmse    standard   2916.825    10 142.2611 pre0_m…\n 6    0.00000001            7 rmse    standard   2964.744    10 151.6287 pre0_m…\n 7    0.0000000001          8 rmse    standard   2968.131    10 151.2367 pre0_m…\n 8    0.0001               13 rmse    standard   2982.908    10 181.7075 pre0_m…\n 9    0.0001                8 rmse    standard   2985.039    10 141.9807 pre0_m…\n10    0.000000001           7 rmse    standard   2985.552    10 177.6839 pre0_m…\n# ℹ 90 more rows\n\n\nWow, this highly flexible model seems to be surfacing non-linear relationships between our response and predictors, as we now have a much lower cross-validated RMSE. Let’s capture the hyperparameters corresponding to the best fit.\n\n#Capturing best bagged tree model\nbag_best_params&lt;-select_best(bag_fit, metric = \"rmse\")\n\n#Printing hyperparameter values\nbag_best_params\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config          \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;            \n1      0.00000001         13 pre0_mod029_post0\n\n\nOur “best” combination of hyperparameters is a tree depth of 11 and cost complexity of 0.00001.\n\n\nRandom Forest\nLet’s tune our final model class: the random forest. As we did for the other models, we need to specify the model and engine.\n\n#Specifying model and engine for random forest\nrf_model&lt;-rand_forest(mtry = tune(),\n                          min_n = 5,\n                          trees = 2000) |&gt;\n  set_engine(\"ranger\", importance = \"impurity\") |&gt;\n  set_mode(\"regression\")\n\n#Creating random forest workflow\nrf_wkf&lt;-workflow() |&gt;\n  add_recipe(bike_rec_1) |&gt;\n  add_model(rf_model)\n\nNote that we are holding the number of trees in each forest and the number of observations per endpoint constant, while we are tuning the number of predictors we are considering at each split (mtry).\nLet’s use cross-validation to identify the “best” value of mtry.\n\n#Setting seed for reproducibility when rerunning chunk\nset.seed(10)\n\n#Fitting random forest model across values of mtry\nrf_fit&lt;-rf_wkf |&gt;\n  tune_grid(resamples = folds,\n            grid = grid_regular(mtry(range = c(1,13)), levels = 13),\n            metrics = metric_set(rmse)) \n\nWe print the cross-validated RMSE values for each value of mtry below.\n\n#Sorting models by RMSE\nrf_fit |&gt; collect_metrics() |&gt;\n  arrange(mean)\n\n# A tibble: 13 × 7\n    mtry .metric .estimator     mean     n  std_err .config         \n   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;           \n 1    13 rmse    standard   2832.662    10 135.1595 pre0_mod13_post0\n 2    12 rmse    standard   2840.388    10 135.2537 pre0_mod12_post0\n 3    11 rmse    standard   2851.000    10 140.4613 pre0_mod11_post0\n 4    10 rmse    standard   2858.172    10 144.8538 pre0_mod10_post0\n 5     9 rmse    standard   2883.635    10 144.8365 pre0_mod09_post0\n 6     8 rmse    standard   2905.989    10 149.2997 pre0_mod08_post0\n 7     7 rmse    standard   2936.812    10 155.2607 pre0_mod07_post0\n 8     6 rmse    standard   2982.730    10 159.1785 pre0_mod06_post0\n 9     5 rmse    standard   3015.448    10 166.4954 pre0_mod05_post0\n10     4 rmse    standard   3088.323    10 169.9006 pre0_mod04_post0\n11     3 rmse    standard   3193.385    10 183.3893 pre0_mod03_post0\n12     2 rmse    standard   3520.632    10 180.5856 pre0_mod02_post0\n13     1 rmse    standard   4866.414    10 169.4948 pre0_mod01_post0\n\n\nThe random forest also posts relatively low RMSE values for the top models. Let’s extract the best-performing value of mtry and see how our best models from each model family perform on the test set.\n\n#Capturing best random forest model\nrf_best_params&lt;-select_best(rf_fit, metric = \"rmse\")\n\n#Printing hyperparameter values\nrf_best_params\n\n# A tibble: 1 × 2\n   mtry .config         \n  &lt;int&gt; &lt;chr&gt;           \n1    13 pre0_mod13_post0\n\n\nThe “best” model randomly selects 12 predictors from the 13 total predictors.\n\n\nTest Set Performance\nNow that we have tuned each model type, we will fit the best models to the full training set and test on the test set. This will allow us to select a final model.\nFirst, we will fit the LASSO model.\n\n#Setting LASSO hyperparameter values to those selected via CV\nlasso_final_wkf&lt;-lasso_wkf |&gt;\n  finalize_workflow(lasso_best_params)\n\n#Fitting final model to the full training set and testing on original test set\nlasso_final_fit&lt;-lasso_final_wkf |&gt;\n  last_fit(bike_share_split, metrics = metric_set(rmse, mae))\n\nSecond, we will fit the regression tree model.\n\n#Setting regression tree hyperparameter values to those selected via CV\ntree_final_wkf&lt;-tree_wkf |&gt;\n  finalize_workflow(tree_best_params)\n\n#Fitting final model to the full training set and testing on original test set\ntree_final_fit&lt;-tree_final_wkf |&gt;\n  last_fit(bike_share_split, metrics = metric_set(rmse, mae))\n\nThird, we will fit the bagged tree model.\n\n#Setting seed for reproducibility when we rerun this chunk\nset.seed(10)\n\n#Setting bagged tree hyperparameter values to those selected via CV\nbag_final_wkf&lt;-bag_wkf |&gt;\n  finalize_workflow(bag_best_params)\n\n#Fitting final model to the full training set and testing on original test set\nbag_final_fit&lt;-bag_final_wkf |&gt;\n  last_fit(bike_share_split, metrics = metric_set(rmse, mae))\n\nFinally, we will fit the random forest model.\n\n#Setting seed for reproducibility when we rerun this chunk\nset.seed(10)\n\n#Setting rf hyperparameter values to those selected via CV\nrf_final_wkf&lt;-rf_wkf |&gt;\n  finalize_workflow(rf_best_params)\n\n#Fitting final model to the full training set and testing on original test set\nrf_final_fit&lt;-rf_final_wkf |&gt;\n  last_fit(bike_share_split, metrics = metric_set(rmse, mae))\n\nLet’s print the test RMSE and mean absolute error (MAE) to see which model predicted best on the test set. Note that we are including the best MLR model in this table.\n\n#Printing RMSE and MAE for the best models of each class\nrbind(final_fit |&gt; collect_metrics() |&gt; mutate(model = \"MLR\") |&gt; select(model, everything()),\n      lasso_final_fit |&gt; collect_metrics() |&gt; mutate(model = \"LASSO\") |&gt; select(model, everything()),\n      tree_final_fit |&gt; collect_metrics() |&gt; mutate(model = \"Reg Tree\") |&gt; select(model, everything()),\n      bag_final_fit |&gt; collect_metrics() |&gt; mutate(model = \"Bagged Tree\") |&gt; select(model, everything()),\n      rf_final_fit |&gt; collect_metrics() |&gt; mutate(model = \"Random Forest\") |&gt; select(model, everything()))\n\n# A tibble: 10 × 5\n   model         .metric .estimator .estimate .config        \n   &lt;chr&gt;         &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;          \n 1 MLR           rmse    standard    2963.439 pre0_mod0_post0\n 2 MLR           mae     standard    2181.411 pre0_mod0_post0\n 3 LASSO         rmse    standard    3553.590 pre0_mod0_post0\n 4 LASSO         mae     standard    2808.288 pre0_mod0_post0\n 5 Reg Tree      rmse    standard    3731.833 pre0_mod0_post0\n 6 Reg Tree      mae     standard    2689.069 pre0_mod0_post0\n 7 Bagged Tree   rmse    standard    2884.980 pre0_mod0_post0\n 8 Bagged Tree   mae     standard    2157.208 pre0_mod0_post0\n 9 Random Forest rmse    standard    2880.980 pre0_mod0_post0\n10 Random Forest mae     standard    2116.634 pre0_mod0_post0\n\n\nThe random forest model predicts daily bike rentals best. There must be some complex non-linear relationships between rentals and the predictors!\n\n\nFit Summaries\nWe have already summarized the fit of the MLR model above by printing the coefficients table. Let’s summarize the fits of the other “best” models in this subsection.\nTo start, we can produce the coefficients table for the best-performing LASSO model.\n\n#Extracting fit summary\nlasso_final_fit |&gt;\n  extract_fit_parsnip() |&gt;\n  tidy() |&gt;\n  kable()\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\nWarning: 'xfun::attr()' is deprecated.\nUse 'xfun::attr2()' instead.\nSee help(\"Deprecated\")\n\n\n\n\n\nterm\nestimate\npenalty\n\n\n\n\n(Intercept)\n20297.4316\n3.511192\n\n\nsnowfall\n-365.8258\n3.511192\n\n\nrainfall\n-1692.8626\n3.511192\n\n\ntemperature\n0.0000\n3.511192\n\n\nhumidity\n-1200.1146\n3.511192\n\n\nwind_speed\n-610.0563\n3.511192\n\n\nvisibility\n-121.8673\n3.511192\n\n\ndew_point\n4213.6689\n3.511192\n\n\nradiation\n4046.7767\n3.511192\n\n\nseason_Spring\n-4772.8353\n3.511192\n\n\nseason_Summer\n-3470.6032\n3.511192\n\n\nseason_Winter\n-8259.1627\n3.511192\n\n\nholiday_No.Holiday\n2635.4347\n3.511192\n\n\nweekend_yes\n-2623.7216\n3.511192\n\n\n\n\n\nInterestingly, it seems the only coefficient shrunken all the way to 0 is temperature, which I would not have expected. That said, temperature is correlated with several other predictors.\nNow let’s extract the final regression tree fit to the full dataset.\n\n#Extracting final tree fit\ntree_final_fit |&gt;\n  extract_fit_engine() |&gt;\n  rpart.plot::rpart.plot(roundint = FALSE)\n\n\n\n\n\n\n\n\nMaybe the most intriguing fact is that the tree’s first split is based on temperature, the same variable our final LASSO fit excluded.\nLet’s plot the variable important metrics from the final bagged tree model to see what role temperature played across the bagged trees.\n\n#Extracting fit information for bagged tree\nbag_final_fit_metrics&lt;-extract_fit_engine(bag_final_fit)\n\n#Creating plot of variable importance metrics\nbag_final_fit_metrics$imp |&gt;\n  mutate(term = factor(term, levels=term)) |&gt;\n  ggplot(aes(x = term, y = value)) +\n  geom_bar(stat = \"identity\") +\n  coord_flip() + labs(title = \"Variable Important for Bagged Tree Model\",y = \"Variable Importance\", x = NULL)\n\n\n\n\n\n\n\n\nAs the importance values are based on reductions in the sum of squared errors and the scale of our response is relatively highly, tens of thousands of rentals per day, our variable importance metrics are massive. However, this is not of particular importance. What’s important is the relative importance levels. Note that temperature has the largest value, indicating it directly contributes the most to our predictive accuracy. This aligns with our basic regression tree model and contrasts with our final LASSO model.\n\n#Creating variable importance metrics for random forest\nrf_final_fit |&gt;\n  extract_fit_parsnip() |&gt;\n  vip(num_features = 13) + labs(title = \"Variable Important for Random Forest Model\", y = \"Variable Importance\")\n\n\n\n\n\n\n\n\nIn general, these variable importance metrics are similar to those of the bagged tree model. However, there are some notable differences. For example, radiation has the second-highest important score in the final random forest model fit to the entire training set, while it only has the fourth-highest score in the bagged tree model.\n\n\nFitting our Final Model to the Full Dataset\nIf we want to deploy our best model across all classes for future predictions, we want to refit it to the entire dataset to ensure we are predicting based on all available information. As the best random forest model produced the lowest RMSE and MAE when fit to the full training set and tested on the full test set, we declared it our best overall model. Thus, that is the model we will fit to the full dataset.\n\n#Fitting model to the full dataset\nfinal_model&lt;- rf_final_wkf |&gt;\n  fit(bike_share_data)\n\n#Printing final model information\nfinal_model\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_date()\n• step_mutate()\n• step_rm()\n• step_normalize()\n• step_dummy()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~13L,      x), num.trees = ~2000, min.node.size = min_rows(~5, x), importance = ~\"impurity\",      num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1)) \n\nType:                             Regression \nNumber of trees:                  2000 \nSample size:                      353 \nNumber of independent variables:  13 \nMtry:                             13 \nTarget node size:                 5 \nVariable importance mode:         impurity \nSplitrule:                        variance \nOOB prediction error (MSE):       7589054 \nR squared (OOB):                  0.9231467 \n\n\nNow we are ready to deploy our model!"
  }
]